# Today I Learned

## March 21, 2023

- Classification: K-Nearest Neighbors (KNN) algorithm
  - Learned how to build a KNN model to make predictions and how to access the model's accuracy
  - Clarified the concepts of underfitting and overfitting in machine learning
  - Discovered an effective way to see the change of accuracy according to the number of neighbors by using a for loop

## March 22, 2023

- Git
  - I was supposed to take a lesson regarding regression.
  - Instead, today I learned how to use Git to manage version control for my code projects.
  - It took some time and effort, but I successfully connected Git and GitHub, and also integrated Git with my Jupyter Notebook workflow.
  - I am writing this on Jupyter notebook, and it will be automatically in my GitHub page. Amazing!
  
## March 23, 2023

- Regression
  - I learned that in scikit-learn, features must be represented as a two-dimensional array.
  - I figured out that if I have a one-dimensional feature vector, I can convert it into a two-dimensional feature matrix with one column using NumPy's reshape() method, which is the required format for scikit-learn.

## March 24, 2023

- Even though I was tired from a job interview earlier today, I was determined to dedicate my time to learning regression models.
- Regression
  - During my review of regression models, I focused on two common evaluation metrics: R-squared (R^2) and Root Mean Squared Error (RMSE).
  - At first, I was confused about how to calculate these metrics using Python. However, I was able to figure it out and now have a better understanding of how to use libraries like sklearn.metrics and numpy to compute R^2 and RMSE for regression models.
